Mon Jul  7 11:40:42 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-SXM-64GB            On | 00000000:1D:00.0 Off |                    0 |
| N/A   43C    P0               63W / 469W|      0MiB / 65536MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA A100-SXM-64GB            On | 00000000:56:00.0 Off |                    0 |
| N/A   43C    P0               65W / 471W|      0MiB / 65536MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA A100-SXM-64GB            On | 00000000:8F:00.0 Off |                    0 |
| N/A   43C    P0               60W / 459W|      0MiB / 65536MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA A100-SXM-64GB            On | 00000000:C8:00.0 Off |                    0 |
| N/A   43C    P0               64W / 458W|      0MiB / 65536MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
+ -------------- SLURM CHECK -------------- +
CUDA_VISIBLE_DEVICES=0,1,2,3
NODES=1
+ ----------------------------------------- +
+ ---------- TORCH LIBRARY CHECK ---------- +
PyTorch version: 2.7.1+cu126
PyTorch CUDA version: 12.6
PyTorch CUDNN version: 90501
GPUs per node 4
Training with GPUs :)
+ ----------------------------------------- +
[Rank 0] GPU_RANK=0 on CUDA device 0 hostname=lrdn0461.leonardo.local
[Rank 1] GPU_RANK=1 on CUDA device 1 hostname=lrdn0461.leonardo.local
[Rank 2] GPU_RANK=2 on CUDA device 2 hostname=lrdn0461.leonardo.local
[Rank 3] GPU_RANK=3 on CUDA device 3 hostname=lrdn0461.leonardo.local
[RANK 0] This dataset has 60000 samples
[RANK 0] I have 60000 samples. From 0 to 60000
[RANK 0] Trainer is running...
[RANK 0 GPU 0] Epoch 0 | Batches: 40
-> Epoch 0 | Avg Loss: 0.050608465701658674
[RANK 0 GPU 0] Epoch 1 | Batches: 40
