W0707 11:32:01.049000 2063276 site-packages/torch/distributed/run.py:766] 
W0707 11:32:01.049000 2063276 site-packages/torch/distributed/run.py:766] *****************************************
W0707 11:32:01.049000 2063276 site-packages/torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0707 11:32:01.049000 2063276 site-packages/torch/distributed/run.py:766] *****************************************
W0707 11:32:01.050000 2063277 site-packages/torch/distributed/run.py:766] 
W0707 11:32:01.050000 2063277 site-packages/torch/distributed/run.py:766] *****************************************
W0707 11:32:01.050000 2063277 site-packages/torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0707 11:32:01.050000 2063277 site-packages/torch/distributed/run.py:766] *****************************************
W0707 11:32:01.050000 2063278 site-packages/torch/distributed/run.py:766] 
W0707 11:32:01.050000 2063278 site-packages/torch/distributed/run.py:766] *****************************************
W0707 11:32:01.050000 2063278 site-packages/torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0707 11:32:01.050000 2063278 site-packages/torch/distributed/run.py:766] *****************************************
W0707 11:32:01.050000 2063279 site-packages/torch/distributed/run.py:766] 
W0707 11:32:01.050000 2063279 site-packages/torch/distributed/run.py:766] *****************************************
W0707 11:32:01.050000 2063279 site-packages/torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0707 11:32:01.050000 2063279 site-packages/torch/distributed/run.py:766] *****************************************
/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W707 11:32:08.749359994 ProcessGroupNCCL.cpp:4718] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
[rank2]:[W707 11:32:08.749361645 ProcessGroupNCCL.cpp:4718] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
[rank0]:[W707 11:32:08.755959223 ProcessGroupNCCL.cpp:4718] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W707 11:32:08.768521012 ProcessGroupNCCL.cpp:4718] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
[rank0]:[W707 11:32:08.209544844 ProcessGroupNCCL.cpp:4718] [PG ID 1 PG GUID 1 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.
Traceback (most recent call last):
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ~~~~^^
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/run.py", line 892, in main
    run(args)
    ~~~^^^^^^
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/run.py", line 883, in run
    elastic_launch(
    ~~~~~~~~~~~~~~~
        config=config,
        ~~~~~~~~~~~~~~
        entrypoint=cmd,
        ~~~~~~~~~~~~~~~
    )(*cmd_args)
    ~^^^^^^^^^^^
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/launcher/api.py", line 139, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/launcher/api.py", line 265, in launch_agent
    if result.is_failed():
       ^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'is_failed'
[W707 11:32:48.858539531 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=3, addr=[lrdn1901.leonardo.local]:35386, remote=[lrdn1901.leonardo.local]:29600): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x14bdd42225e8 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x14be13e3fbfe in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x14be13e41458 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x14be13e42c3e in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::doWait(c10::ArrayRef<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0x1a6 (0x14be13e3cbc6 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::TCPStore::doGet(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x33 (0x14be13e3cfa3 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::TCPStore::get(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0xab (0x14be13e3e08b in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #7: <unknown function> + 0xc12dd6 (0x14be22d12dd6 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x38174d (0x14be2248174d in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x1d3c2c (0x5631f8b48c2c in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #10: _PyObject_MakeTpCall + 0x36c (0x5631f8b2507c in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #11: <unknown function> + 0x206341 (0x5631f8b7b341 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #12: <unknown function> + 0x9ea1c (0x5631f8a13a1c in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #13: <unknown function> + 0x273463 (0x5631f8be8463 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #14: <unknown function> + 0x2c1d4a (0x5631f8c36d4a in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #15: <unknown function> + 0x2816d5 (0x5631f8bf66d5 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #16: <unknown function> + 0x9ea1c (0x5631f8a13a1c in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #17: PyEval_EvalCode + 0xa1 (0x5631f8bea171 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #18: <unknown function> + 0x2b3010 (0x5631f8c28010 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #19: <unknown function> + 0x2b09cc (0x5631f8c259cc in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #20: <unknown function> + 0x2ad876 (0x5631f8c22876 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #21: <unknown function> + 0x2ad4a8 (0x5631f8c224a8 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #22: <unknown function> + 0x2ad2bc (0x5631f8c222bc in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #23: Py_RunMain + 0x32e (0x5631f8c206ae in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #24: Py_BytesMain + 0x37 (0x5631f8bd5d97 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #25: __libc_start_main + 0xe5 (0x14be2b180d85 in /lib64/libc.so.6)
frame #26: <unknown function> + 0x26018e (0x5631f8bd518e in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)

W0707 11:32:48.394000 2063279 site-packages/torch/distributed/elastic/rendezvous/dynamic_rendezvous.py:1292] The node 'lrdn1901.leonardo.local_2063279_0' has failed to shutdown the rendezvous '17437024' due to an error of type RendezvousConnectionError.
[W707 11:32:48.870361174 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=3, addr=[lrdn1901-net6-3.leonardo.local]:35386, remote=[lrdn1901.leonardo.local]:29600): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x14bdd42225e8 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x14be13e3fbfe in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x14be13e41458 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x14be13e42c3e in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::doWait(c10::ArrayRef<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0x1a6 (0x14be13e3cbc6 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::TCPStore::doGet(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x33 (0x14be13e3cfa3 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::TCPStore::get(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0xab (0x14be13e3e08b in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #7: <unknown function> + 0xc12dd6 (0x14be22d12dd6 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x38174d (0x14be2248174d in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x1d3c2c (0x5631f8b48c2c in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #10: _PyObject_MakeTpCall + 0x36c (0x5631f8b2507c in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #11: <unknown function> + 0x206341 (0x5631f8b7b341 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #12: <unknown function> + 0x9ea1c (0x5631f8a13a1c in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #13: <unknown function> + 0x273463 (0x5631f8be8463 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #14: <unknown function> + 0x2c1d4a (0x5631f8c36d4a in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #15: <unknown function> + 0x2816d5 (0x5631f8bf66d5 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #16: <unknown function> + 0x9ea1c (0x5631f8a13a1c in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #17: PyEval_EvalCode + 0xa1 (0x5631f8bea171 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #18: <unknown function> + 0x2b3010 (0x5631f8c28010 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #19: <unknown function> + 0x2b09cc (0x5631f8c259cc in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #20: <unknown function> + 0x2ad876 (0x5631f8c22876 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #21: <unknown function> + 0x2ad4a8 (0x5631f8c224a8 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #22: <unknown function> + 0x2ad2bc (0x5631f8c222bc in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #23: Py_RunMain + 0x32e (0x5631f8c206ae in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #24: Py_BytesMain + 0x37 (0x5631f8bd5d97 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #25: __libc_start_main + 0xe5 (0x14be2b180d85 in /lib64/libc.so.6)
frame #26: <unknown function> + 0x26018e (0x5631f8bd518e in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)

W0707 11:32:48.404000 2063279 site-packages/torch/distributed/elastic/rendezvous/dynamic_rendezvous.py:1292] The node 'lrdn1901.leonardo.local_2063279_0' has failed to shutdown the rendezvous '17437024' due to an error of type RendezvousConnectionError.
Traceback (most recent call last):
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/rendezvous/c10d_rendezvous_backend.py", line 117, in _call_store
    return getattr(self._store, store_op)(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
torch.distributed.DistNetworkError: failed to recv, got 0 bytes

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ~~~~^^
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/run.py", line 892, in main
    run(args)
    ~~~^^^^^^
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/run.py", line 883, in run
    elastic_launch(
    ~~~~~~~~~~~~~~~
        config=config,
        ~~~~~~~~~~~~~~
        entrypoint=cmd,
        ~~~~~~~~~~~~~~~
    )(*cmd_args)
    ~^^^^^^^^^^^
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/launcher/api.py", line 139, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/launcher/api.py", line 261, in launch_agent
    result = agent.run()
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/metrics/api.py", line 138, in wrapper
    result = f(*args, **kwargs)
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/agent/server/api.py", line 711, in run
    result = self._invoke_run(role)
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/agent/server/api.py", line 864, in _invoke_run
    self._initialize_workers(self._worker_group)
    ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/metrics/api.py", line 138, in wrapper
    result = f(*args, **kwargs)
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/agent/server/api.py", line 683, in _initialize_workers
    self._rendezvous(worker_group)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/metrics/api.py", line 138, in wrapper
    result = f(*args, **kwargs)
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/agent/server/api.py", line 500, in _rendezvous
    rdzv_info = spec.rdzv_handler.next_rendezvous()
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/rendezvous/dynamic_rendezvous.py", line 1170, in next_rendezvous
    self._op_executor.run(join_op, deadline, self._get_deadline)
    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/rendezvous/dynamic_rendezvous.py", line 648, in run
    has_set = self._state_holder.sync()
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/rendezvous/dynamic_rendezvous.py", line 437, in sync
    get_response = self._backend.get_state()
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/rendezvous/c10d_rendezvous_backend.py", line 75, in get_state
    base64_state: bytes = self._call_store("get", self._key)
                          ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/rendezvous/c10d_rendezvous_backend.py", line 119, in _call_store
    raise RendezvousConnectionError(
        "The connection to the C10d store has failed. See inner exception for details."
    ) from exc
torch.distributed.elastic.rendezvous.api.RendezvousConnectionError: The connection to the C10d store has failed. See inner exception for details.
[W707 11:32:48.904563024 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=3, addr=[lrdn1901-net6-3.leonardo.local]:35402, remote=[lrdn1901.leonardo.local]:29600): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x14a58f4c95e8 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x14a5cf0e6bfe in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x14a5cf0e8458 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x14a5cf0e9c3e in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::doWait(c10::ArrayRef<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0x1a6 (0x14a5cf0e3bc6 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::TCPStore::doGet(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x33 (0x14a5cf0e3fa3 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::TCPStore::get(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0xab (0x14a5cf0e508b in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #7: <unknown function> + 0xc12dd6 (0x14a5ddfb9dd6 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x38174d (0x14a5dd72874d in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x1d3c2c (0x560a73ea3c2c in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #10: _PyObject_MakeTpCall + 0x36c (0x560a73e8007c in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #11: <unknown function> + 0x206341 (0x560a73ed6341 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #12: <unknown function> + 0x9ea1c (0x560a73d6ea1c in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #13: <unknown function> + 0x273463 (0x560a73f43463 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #14: <unknown function> + 0x2c1d4a (0x560a73f91d4a in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #15: <unknown function> + 0x2816d5 (0x560a73f516d5 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #16: <unknown function> + 0x9ea1c (0x560a73d6ea1c in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #17: PyEval_EvalCode + 0xa1 (0x560a73f45171 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #18: <unknown function> + 0x2b3010 (0x560a73f83010 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #19: <unknown function> + 0x2b09cc (0x560a73f809cc in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #20: <unknown function> + 0x2ad876 (0x560a73f7d876 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #21: <unknown function> + 0x2ad4a8 (0x560a73f7d4a8 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #22: <unknown function> + 0x2ad2bc (0x560a73f7d2bc in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #23: Py_RunMain + 0x32e (0x560a73f7b6ae in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #24: Py_BytesMain + 0x37 (0x560a73f30d97 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #25: __libc_start_main + 0xe5 (0x14a5e6427d85 in /lib64/libc.so.6)
frame #26: <unknown function> + 0x26018e (0x560a73f3018e in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)

W0707 11:32:48.440000 2063277 site-packages/torch/distributed/elastic/rendezvous/dynamic_rendezvous.py:1292] The node 'lrdn1901.leonardo.local_2063277_0' has failed to shutdown the rendezvous '17437024' due to an error of type RendezvousConnectionError.
[W707 11:32:48.915233512 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=3, addr=[lrdn1901.leonardo.local]:35402, remote=[lrdn1901.leonardo.local]:29600): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x14a58f4c95e8 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x14a5cf0e6bfe in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x14a5cf0e8458 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x14a5cf0e9c3e in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::doWait(c10::ArrayRef<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0x1a6 (0x14a5cf0e3bc6 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::TCPStore::doGet(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x33 (0x14a5cf0e3fa3 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::TCPStore::get(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0xab (0x14a5cf0e508b in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_cpu.so)
frame #7: <unknown function> + 0xc12dd6 (0x14a5ddfb9dd6 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x38174d (0x14a5dd72874d in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x1d3c2c (0x560a73ea3c2c in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #10: _PyObject_MakeTpCall + 0x36c (0x560a73e8007c in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #11: <unknown function> + 0x206341 (0x560a73ed6341 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #12: <unknown function> + 0x9ea1c (0x560a73d6ea1c in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #13: <unknown function> + 0x273463 (0x560a73f43463 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #14: <unknown function> + 0x2c1d4a (0x560a73f91d4a in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #15: <unknown function> + 0x2816d5 (0x560a73f516d5 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #16: <unknown function> + 0x9ea1c (0x560a73d6ea1c in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #17: PyEval_EvalCode + 0xa1 (0x560a73f45171 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #18: <unknown function> + 0x2b3010 (0x560a73f83010 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #19: <unknown function> + 0x2b09cc (0x560a73f809cc in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #20: <unknown function> + 0x2ad876 (0x560a73f7d876 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #21: <unknown function> + 0x2ad4a8 (0x560a73f7d4a8 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #22: <unknown function> + 0x2ad2bc (0x560a73f7d2bc in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #23: Py_RunMain + 0x32e (0x560a73f7b6ae in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #24: Py_BytesMain + 0x37 (0x560a73f30d97 in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)
frame #25: __libc_start_main + 0xe5 (0x14a5e6427d85 in /lib64/libc.so.6)
frame #26: <unknown function> + 0x26018e (0x560a73f3018e in /leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/python3.13)

W0707 11:32:48.449000 2063277 site-packages/torch/distributed/elastic/rendezvous/dynamic_rendezvous.py:1292] The node 'lrdn1901.leonardo.local_2063277_0' has failed to shutdown the rendezvous '17437024' due to an error of type RendezvousConnectionError.
Traceback (most recent call last):
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/rendezvous/c10d_rendezvous_backend.py", line 117, in _call_store
    return getattr(self._store, store_op)(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
torch.distributed.DistNetworkError: failed to recv, got 0 bytes

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ~~~~^^
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/run.py", line 892, in main
    run(args)
    ~~~^^^^^^
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/run.py", line 883, in run
    elastic_launch(
    ~~~~~~~~~~~~~~~
        config=config,
        ~~~~~~~~~~~~~~
        entrypoint=cmd,
        ~~~~~~~~~~~~~~~
    )(*cmd_args)
    ~^^^^^^^^^^^
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/launcher/api.py", line 139, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/launcher/api.py", line 261, in launch_agent
    result = agent.run()
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/metrics/api.py", line 138, in wrapper
    result = f(*args, **kwargs)
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/agent/server/api.py", line 711, in run
    result = self._invoke_run(role)
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/agent/server/api.py", line 864, in _invoke_run
    self._initialize_workers(self._worker_group)
    ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/metrics/api.py", line 138, in wrapper
    result = f(*args, **kwargs)
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/agent/server/api.py", line 683, in _initialize_workers
    self._rendezvous(worker_group)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/metrics/api.py", line 138, in wrapper
    result = f(*args, **kwargs)
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/agent/server/api.py", line 500, in _rendezvous
    rdzv_info = spec.rdzv_handler.next_rendezvous()
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/rendezvous/dynamic_rendezvous.py", line 1170, in next_rendezvous
    self._op_executor.run(join_op, deadline, self._get_deadline)
    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/rendezvous/dynamic_rendezvous.py", line 648, in run
    has_set = self._state_holder.sync()
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/rendezvous/dynamic_rendezvous.py", line 437, in sync
    get_response = self._backend.get_state()
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/rendezvous/c10d_rendezvous_backend.py", line 75, in get_state
    base64_state: bytes = self._call_store("get", self._key)
                          ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^
  File "/leonardo/home/userexternal/lpiarull/.conda/envs/fddl/lib/python3.13/site-packages/torch/distributed/elastic/rendezvous/c10d_rendezvous_backend.py", line 119, in _call_store
    raise RendezvousConnectionError(
        "The connection to the C10d store has failed. See inner exception for details."
    ) from exc
torch.distributed.elastic.rendezvous.api.RendezvousConnectionError: The connection to the C10d store has failed. See inner exception for details.
srun: error: lrdn1901: task 0: Exited with exit code 1
srun: error: lrdn1901: tasks 1,3: Exited with exit code 1
